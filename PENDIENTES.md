# üìã PENDIENTES D8

**√öltima actualizaci√≥n:** 2025-11-21  
**Estado actual:** ‚úÖ FASE 2 + TELEGRAM BOT + FILESYSTEM MANAGEMENT + SUPERVISOR OPERACIONAL

---

## ü§ñ SISTEMA DE GESTI√ìN DE TAREAS CON AGENTES PARALELOS (2025-11-21) - PENDIENTE

### Task Distribution System (TDS) - Sistema Robusto de Trabajo Paralelo

**Estado:** ‚è≥ PENDIENTE  
**Prioridad:** üî• ALTA  
**Fecha de creaci√≥n:** 2025-11-21  
**Estimaci√≥n:** 8-12 d√≠as (implementaci√≥n incremental)  
**Dise√±ado por:** GitHub Copilot + Metodolog√≠a D8

#### üìã Contexto

D8 tiene 2342 l√≠neas de pendientes en `PENDIENTES.md` que necesitan procesarse eficientemente. Actualmente no existe un sistema que permita:
- Parsear pendientes autom√°ticamente
- Asignar tareas a m√∫ltiples agentes en paralelo
- Evitar conflictos (2 agentes trabajando en lo mismo)
- Gestionar branches de Git autom√°ticamente
- Trackear progreso en tiempo real

#### üéØ Objetivo

Crear un sistema profesional y robusto que permita a m√∫ltiples agentes (instancias del Congreso Aut√≥nomo) trabajar simult√°neamente en diferentes pendientes sin interferencias, usando:
- **Branches de Git** para isolation (cada tarea = 1 branch)
- **File-based locks** para prevenir race conditions
- **Orchestration inteligente** para asignaci√≥n y monitoring

#### üèóÔ∏è Arquitectura Propuesta

```
TASK DISTRIBUTION SYSTEM
‚îú‚îÄ‚îÄ Task Parser          ‚Üí Extrae tareas desde PENDIENTES.md
‚îú‚îÄ‚îÄ Task Queue           ‚Üí Cola priorizada thread-safe
‚îú‚îÄ‚îÄ Lock Manager         ‚Üí Previene conflictos (file-based o Redis)
‚îú‚îÄ‚îÄ Git Manager          ‚Üí Gesti√≥n autom√°tica de branches
‚îú‚îÄ‚îÄ Task Coordinator     ‚Üí Asigna y supervisa agentes
‚îú‚îÄ‚îÄ Agent Worker         ‚Üí Wrapper para AutonomousCongress
‚îî‚îÄ‚îÄ PR Manager           ‚Üí Auto-merge + validaci√≥n
```

#### üì¶ Componentes Detallados

**1. Task Parser** (`app/tasks/parser.py`)
- Parsear Markdown con headers, prioridades, estados
- Detectar metadata: `Estado: ‚è≥ PENDIENTE`, `Prioridad: üî• CR√çTICA`
- Generar ID √∫nico por tarea (hash del contenido)
- Detectar dependencias entre tareas
- Estimar complejidad (l√≠neas, archivos afectados)

**Schema de Tarea:**
```python
@dataclass
class ParsedTask:
    task_id: str                    # Hash √∫nico
    title: str                      # T√≠tulo de la secci√≥n
    description: str                # Contenido completo
    priority: int                   # 1-5 (CR√çTICA=5)
    status: str                     # PENDIENTE, EN_PROCESO, COMPLETADO
    estimated_complexity: int       # 1-10
    files_to_modify: List[str]      # Archivos afectados
    dependencies: List[str]         # task_ids de dependencias
    assignable: bool                # ¬øAsignable ahora?
```

**2. Task Queue** (`app/tasks/queue.py`)
- Priority queue (heapq) con locks thread-safe
- Scoring din√°mico: `priority * 100 - complexity * 10 - wait_time`
- Evitar starvation (tareas antiguas suben prioridad)
- Filtrar tareas asignables (sin dependencias bloqueadas)

**3. Lock Manager** (`app/tasks/lock_manager.py`)
- **Opci√≥n A (MVP):** File-based locks en `~/Documents/d8_data/locks/`
  - Lock por tarea: `task_{task_id}.lock`
  - Lock por archivo: `file_{filepath_hash}.lock`
  - TTL de 1 hora (auto-expiraci√≥n)
- **Opci√≥n B (Escalable):** Redis-based locks
  - TTL autom√°tico
  - Atomic operations
  - Funciona en cluster distribuido

**4. Git Manager** (`app/tasks/git_manager.py`)
- Crear branch por tarea: `task/{task_id}-{slug}`
- Switch autom√°tico al asignar
- Push autom√°tico al completar
- Crear PR en GitHub via API
- Auto-merge si no hay conflictos
- Detecci√≥n de merge conflicts

**5. Task Coordinator** (`app/tasks/coordinator.py`)
- Pool de N agentes (configurable)
- Asignaci√≥n inteligente (match skills con tarea)
- Heartbeat monitoring (detectar agentes colgados)
- Rebalanceo autom√°tico
- Loop principal cada 60s

**6. Agent Worker** (`app/tasks/agent_worker.py`)
- Wrapper para ejecutar `AutonomousCongress` en tarea espec√≠fica
- Threading/multiprocessing para paralelizaci√≥n
- Callback al completar/fallar
- Timeout de 60 minutos por tarea

#### üîÑ Flujo End-to-End

**Ejemplo: 3 agentes trabajan en paralelo**

1. **Inicio:** `python scripts/start_task_system.py --agents 3`
2. **Parsing:** Extrae 10 tareas desde `PENDIENTES.md`
3. **Asignaci√≥n:**
   - Agent-1 ‚Üí Tarea 1 (CR√çTICA) ‚Üí branch `task/001-install-slave`
   - Agent-2 ‚Üí Tarea 2 (ALTA) ‚Üí branch `task/002-supervisor`
   - Agent-3 ‚Üí Tarea 3 (MEDIA) ‚Üí branch `task/003-logging`
4. **Trabajo Paralelo:**
   - Cada agente ejecuta `AutonomousCongress` en su branch
   - Locks previenen modificaciones concurrentes del mismo archivo
   - Monitoring cada 30s (heartbeat)
5. **Completion:**
   - Commit + push autom√°tico
   - Crear PR en GitHub
   - Auto-merge si no hay conflictos
   - Notificar Telegram: "‚úÖ Tarea completada"
   - Asignar siguiente tarea al agente liberado
6. **Desbloqueo:** Si Tarea 2 completa, Tarea 5 (que depend√≠a de 2) se vuelve asignable

#### üóÇÔ∏è Estructura de Archivos

```
d8/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ tasks/                     # NUEVO
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ parser.py              # Task Parser
‚îÇ       ‚îú‚îÄ‚îÄ queue.py               # Task Queue
‚îÇ       ‚îú‚îÄ‚îÄ lock_manager.py        # Lock Manager
‚îÇ       ‚îú‚îÄ‚îÄ git_manager.py         # Git Branch Manager
‚îÇ       ‚îú‚îÄ‚îÄ coordinator.py         # Task Coordinator
‚îÇ       ‚îú‚îÄ‚îÄ agent_worker.py        # Agent Worker
‚îÇ       ‚îî‚îÄ‚îÄ models.py              # Pydantic models
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ start_task_system.py       # NUEVO: Script principal
‚îÇ   ‚îî‚îÄ‚îÄ task_cli.py                # NUEVO: CLI para gesti√≥n
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ tasks/                     # NUEVO: Estado persistente
‚îÇ       ‚îú‚îÄ‚îÄ locks/                 # Locks de tareas/archivos
‚îÇ       ‚îú‚îÄ‚îÄ branches/              # Metadata de branches
‚îÇ       ‚îú‚îÄ‚îÄ queue.json             # Estado de la cola
‚îÇ       ‚îî‚îÄ‚îÄ progress/              # Progreso de tareas activas
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ 03_operaciones/
        ‚îî‚îÄ‚îÄ task_distribution_system.md  # Documentaci√≥n
```

#### üöÄ Plan de Implementaci√≥n Incremental

**FASE 1: MVP (2-3 d√≠as)**
- [ ] `TaskParser` - Parsear PENDIENTES.md
- [ ] `TaskQueue` - Cola simple con priorizaci√≥n
- [ ] `FileLockManager` - Locks file-based
- [ ] `GitManager` - Crear/switch branches
- [ ] Script b√°sico `start_task_system.py`
- [ ] **Validaci√≥n:** 1 agente procesa 1 tarea, crea branch, commit + push, crea PR

**FASE 2: Paralelizaci√≥n (1-2 d√≠as)**
- [ ] `TaskCoordinator` completo
- [ ] `AgentWorker` con threading
- [ ] Monitoring de agentes activos
- [ ] Heartbeat detection
- [ ] **Validaci√≥n:** 3 agentes procesan tareas simult√°neamente sin conflictos

**FASE 3: Inteligencia (2-3 d√≠as)**
- [ ] Dependency graph parsing
- [ ] Auto-merge de PRs sin conflictos
- [ ] Detecci√≥n de merge conflicts
- [ ] Dashboard web (Flask)
- [ ] **Validaci√≥n:** Tareas con dependencias se procesan en orden, auto-merge funciona

**FASE 4: Escalabilidad (opcional)**
- [ ] Migrar a RedisLockManager
- [ ] Redis Queue
- [ ] Deployment en m√∫ltiples Raspberry Pi

#### ‚öôÔ∏è Configuraci√≥n

**Archivo:** `~/Documents/d8_data/task_system/config.json`
```json
{
  "max_parallel_agents": 3,
  "task_timeout_minutes": 60,
  "auto_merge_prs": true,
  "auto_merge_conditions": {
    "no_conflicts": true,
    "ci_passed": true,
    "min_files_changed": 10
  },
  "lock_ttl_seconds": 3600,
  "monitoring_interval_seconds": 30,
  "github": {
    "repo": "lsilva5455/d8",
    "base_branch": "docker-workers",
    "pr_labels": ["auto-generated", "task-system"]
  },
  "notifications": {
    "telegram_enabled": true,
    "notify_on": ["completion", "failure", "conflict"]
  }
}
```

#### üîí Seguridad y Robustez

**1. Prevenci√≥n de Deadlocks**
- Lock TTL de 1 hora (auto-expiraci√≥n)
- Detector de circular dependencies
- Timeout por tarea (60 minutos)

**2. Rollback Autom√°tico**
- Si agente falla: `git reset --hard`
- Branch se elimina autom√°ticamente
- Lock se libera

**3. Validaci√≥n Pre-Commit**
- Tests unitarios autom√°ticos
- Linters (flake8, mypy)
- Verificar que no rompe imports

**4. Rate Limiting**
- Max 10 PRs por hora
- Cooldown de 5 minutos entre tareas del mismo agente

#### üìä M√©tricas de √âxito

| M√©trica | Target |
|---------|--------|
| Tareas completadas/d√≠a | 20+ |
| Tasa de auto-merge | >80% |
| Tiempo promedio por tarea | <45min |
| Conflictos que requieren humano | <10% |
| Agentes activos simult√°neos | 3 |

#### üéØ Decisiones Clave

**¬øPor Branch o por Lock?**
**Decisi√≥n: AMBOS**
- **Branch por tarea:** Isolation completo, conflictos se resuelven en PR
- **Locks para archivos:** Previene race conditions durante desarrollo

**Estrategia combinada:**
- Cada agente trabaja en su branch (isolation)
- Locks previenen modificaciones concurrentes del mismo archivo
- Al crear PR, Git detecta conflicts autom√°ticamente

#### üìö Experiencias Profundas Aplicadas

‚úÖ **Map Before Modify:** Parsear PENDIENTES.md completo antes de asignar  
‚úÖ **Sistemas > Disciplina:** Locks FUERZAN que no haya conflictos  
‚úÖ **Seguir el Dato:** Tarea ‚Üí Queue ‚Üí Lock ‚Üí Branch ‚Üí Agent ‚Üí Commit ‚Üí PR

#### ‚ùì Preguntas para Resoluci√≥n Futura

1. ¬øCu√°ntos agentes en paralelo? (recomendado: 3)
2. ¬øAuto-merge de PRs? (o siempre review humana)
3. ¬øRedis o file-based locks? (file-based m√°s simple)
4. ¬øNotificaciones por Telegram? (s√≠/no)

#### üìù Notas T√©cnicas

- Integrar con `AutonomousCongress` existente
- Usar `pathlib` para paths cross-platform
- Logs estructurados en JSON
- Dashboard Flask en puerto 7001
- Compatible con sistema supervisor existente

#### üîó Referencias

- Patron Orchestrator: `docs/06_knowledge_base/memoria/patrones_arquitectura.md`
- Congreso Aut√≥nomo: `docs/06_knowledge_base/experiencias_profundas/congreso_autonomo.md`
- Sistema distribuido actual: `app/distributed/orchestrator.py`

---

## üö® CORRECCIONES CR√çTICAS PARA INSTALACI√ìN AUTOM√ÅTICA DE SLAVES (2025-11-21) - PENDIENTE

### Sistema de Instalaci√≥n Completamente Automatizado para Raspberry Pi Slaves

**Estado:** ‚è≥ PENDIENTE  
**Prioridad:** üî• CR√çTICA  
**Fecha de creaci√≥n:** 2025-11-21  
**Estimaci√≥n:** 4-6 horas

#### üìã Contexto

Durante la instalaci√≥n del primer slave (192.168.4.38), se identificaron m√∫ltiples problemas que impiden una instalaci√≥n completamente automatizada para futuros slaves. El proceso actual requiere intervenci√≥n manual y tiene timeouts/errores que deben corregirse.

#### ‚ùå Problemas Identificados

**1. TIMEOUT EN PIP INSTALL**
- **Ubicaci√≥n:** `app/distributed/build_d8_slave.py` l√≠nea ~277
- **Problema:** Servidor HTTP slave tiene timeout hardcoded de 300s, pero `pip install -r requirements.txt` puede tomar 5-10 minutos
- **Causa:** L√≠nea `timeout=300` no es respetada por el servidor HTTP que tiene su propio timeout interno
- **Impacto:** Build falla con "Command timeout (300s)" aunque el comando necesita m√°s tiempo

**2. REFERENCIA A ARCHIVO INEXISTENTE**
- **Ubicaci√≥n:** `app/distributed/build_d8_slave.py` l√≠neas ~290-305
- **Problema:** Intenta iniciar `app/distributed/slave_server.py` que NO existe en el repositorio
- **L√≠neas problem√°ticas:**
  ```python
  # Iniciar slave_server
  result = self.execute_command(
      f"nohup ./venv/bin/python app/distributed/slave_server.py > slave.log 2>&1 &",
      working_dir=d8_dir,
      timeout=30
  )
  # Verificar que est√° corriendo
  result = self.execute_command(f"pgrep -f slave_server.py", ...)
  ```
- **Realidad:** El servidor HTTP b√°sico (`install_slave_*.sh`) ya est√° corriendo y es suficiente
- **Impacto:** Confusi√≥n en logs, verificaciones in√∫tiles

**3. INSTALACI√ìN MONOL√çTICA SIN PROGRESO**
- **Problema:** `pip install -r requirements.txt` instala 40+ paquetes de golpe sin feedback
- **Impacto:** 
  - Timeout inevitable (300s no alcanza)
  - Sin visibilidad de progreso
  - Si falla, no sabemos en qu√© paquete

**4. NO HAY SCRIPT AUTOMATIZADO COMPLETO**
- **Problema:** Para instalar un nuevo slave se requiere:
  1. SSH manual para copiar script bash
  2. Ejecutar script manualmente (pide password)
  3. Esperar que HTTP est√© online
  4. Ejecutar BuildD8Slave manualmente
  5. Si falla pip, instalar paquetes uno por uno manualmente
- **Impacto:** Proceso tedioso, no escalable, propenso a errores

**5. DELAYS NO ADAPTATIVOS**
- **Ubicaci√≥n:** `app/distributed/build_d8_slave.py` l√≠nea ~507
- **Problema:** Delay de 1s entre reintentos es igual para todas las estrategias
- **Realidad:**
  - Docker instala docker-compose ‚Üí necesita 10s
  - VEnv con pip fallido ‚Üí necesita 5s
  - Native con PEP 668 ‚Üí falla inmediato, 2s suficiente
- **Impacto:** Reintentos in√∫tiles muy r√°pidos o muy lentos

**6. PASSWORD SSH REQUIERE INTERVENCI√ìN**
- **Estado:** Parcialmente resuelto (agregado a `.env`)
- **Problema restante:** 
  - `lib/ssh_helper.py` requiere `sshpass` (no disponible en Windows)
  - `scripts/slave_cmd.ps1` usa SSH nativo que pide password
  - `scripts/ssh_helper.ps1` depende de PuTTY que puede no estar instalado
- **Impacto:** Primera instalaci√≥n siempre requiere escribir password manualmente

#### üéØ Soluciones a Implementar

**SOLUCI√ìN 1: Servidor HTTP con Timeout Configurable**

**Archivo:** `scripts/setup/generate_slave_installer.py` (template del servidor HTTP)
**Cambios:**
```python
# En el template Python del servidor HTTP (l√≠nea ~120):
def do_POST(self):
    if self.path == "/api/execute":
        # ... c√≥digo existente ...
        data = json.loads(body.decode())
        command = data.get('command')
        timeout = data.get('timeout', 300)  # ‚Üê AGREGAR: timeout desde request
        
        result = subprocess.run(
            command,
            shell=True,
            cwd=working_dir,
            capture_output=True,
            text=True,
            timeout=timeout  # ‚Üê USAR: timeout din√°mico
        )
```

**Impacto:** Permite pip installs largos (600s+) sin modificar servidor

---

**SOLUCI√ìN 2: Instalaci√≥n por Etapas con Progreso**

**Archivo:** `app/distributed/build_d8_slave.py`
**M√©todo:** `strategy_venv()` (l√≠neas 254-310)
**Cambios:**
```python
def strategy_venv(self) -> Tuple[bool, str]:
    """ESTRATEGIA B: Instalaci√≥n con venv por etapas"""
    logger.info("üêç ESTRATEGIA B: VEnv (instalaci√≥n por etapas)")
    
    # ... c√≥digo existente hasta crear venv ...
    
    # ETAPA 1: Paquetes b√°sicos (60s)
    logger.info("üì¶ Etapa 1/3: Instalando b√°sicos (Flask, Requests, Dotenv)...")
    result = self.execute_command(
        "./venv/bin/pip install flask==3.0.0 requests==2.31.0 python-dotenv==1.0.0",
        working_dir=d8_dir,
        timeout=60
    )
    if not result["success"]:
        return False, f"Error en etapa 1: {result['stderr']}"
    
    # ETAPA 2: LLM Clients (120s)
    logger.info("üì¶ Etapa 2/3: Instalando LLM clients (Groq, Gemini, Pydantic)...")
    result = self.execute_command(
        "./venv/bin/pip install groq google-generativeai pydantic",
        working_dir=d8_dir,
        timeout=120
    )
    if not result["success"]:
        return False, f"Error en etapa 2: {result['stderr']}"
    
    # ETAPA 3: Resto de requirements (600s)
    logger.info("üì¶ Etapa 3/3: Instalando resto de dependencias (puede tomar 5-8 min)...")
    result = self.execute_command(
        "./venv/bin/pip install -r requirements.txt",
        working_dir=d8_dir,
        timeout=600
    )
    if not result["success"]:
        # No fallar si algunos paquetes opcionales fallan
        logger.warning(f"‚ö†Ô∏è  Algunos paquetes opcionales fallaron: {result['stderr']}")
    
    # Configurar .env
    logger.info("‚öôÔ∏è  Configurando .env...")
    self.execute_command("""cat > .env << 'EOF'
SLAVE_HOST=0.0.0.0
SLAVE_PORT=7600
LOG_LEVEL=INFO
GROQ_API_KEY=${GROQ_API_KEY}
GEMINI_API_KEY=${GEMINI_API_KEY}
GITHUB_TOKEN=${GITHUB_TOKEN}
EOF""", working_dir=d8_dir)
    
    # NO iniciar slave_server.py (no existe, el HTTP b√°sico ya corre)
    logger.info("‚úÖ VEnv instalado, servidor HTTP ya est√° corriendo")
    
    # Verificar que D8 se puede importar
    logger.info("üß™ Validando instalaci√≥n de D8...")
    result = self.execute_command(
        './venv/bin/python -c "from app.agents.base_agent import BaseAgent; print(\'OK\')"',
        working_dir=d8_dir,
        timeout=10
    )
    
    if result["success"] and "OK" in result["stdout"]:
        return True, "VEnv funcionando correctamente - D8 validado"
    else:
        return False, f"Instalaci√≥n incompleta: {result['stderr']}"
```

**Impacto:** 
- Progreso visible en 3 etapas
- Timeouts adecuados por etapa
- No falla por paquetes opcionales
- Valida que D8 funciona antes de confirmar √©xito

---

**SOLUCI√ìN 3: Delays Adaptativos por Estrategia**

**Archivo:** `app/distributed/build_d8_slave.py`
**Ubicaci√≥n:** M√©todo `build()` l√≠nea ~507
**Cambios:**
```python
# Al inicio de la clase BuildD8Slave (l√≠nea ~25):
RETRY_DELAYS = {
    "docker": 10,    # Docker instala docker-compose, necesita tiempo
    "venv": 5,       # Pip puede necesitar tiempo para liberar locks
    "native": 2      # PEP 668 falla inmediato, retry r√°pido
}

# En el loop de estrategias (l√≠nea ~507):
if attempt < max_retries - 1:
    delay = self.RETRY_DELAYS.get(self.current_strategy, 5)
    logger.info(f"‚è≥ Esperando {delay}s antes de reintentar...")
    time.sleep(delay)
```

**Impacto:** Reintentos m√°s inteligentes seg√∫n contexto

---

**SOLUCI√ìN 4: Script de Instalaci√≥n Completa Automatizado**

**Archivo NUEVO:** `scripts/install_new_slave.py`
**Prop√≥sito:** Instalar un slave desde cero sin intervenci√≥n manual
**C√≥digo:**
```python
#!/usr/bin/env python3
"""
Instalaci√≥n completamente automatizada de D8 Slave en Raspberry Pi

Uso:
    python scripts/install_new_slave.py --ip 192.168.4.39 --name slave-rpi-02

Requisitos:
    - .env con SLAVE_SSH_PASSWORD configurado
    - Raspberry Pi con SSH habilitado
    - Python 3 y Git instalados en el slave
"""
import os
import sys
import time
import argparse
import requests
from pathlib import Path
from dotenv import load_dotenv

# Importar helpers existentes
sys.path.insert(0, str(Path(__file__).parent.parent))
from app.distributed.build_d8_slave import BuildD8Slave
from scripts.setup.generate_slave_installer import SlaveInstallerGenerator

def main():
    parser = argparse.ArgumentParser(description='Instalar D8 Slave autom√°ticamente')
    parser.add_argument('--ip', required=True, help='IP del Raspberry Pi')
    parser.add_argument('--name', required=True, help='Nombre del slave (ej: slave-rpi-02)')
    parser.add_argument('--port', default=7600, type=int, help='Puerto HTTP (default: 7600)')
    args = parser.parse_args()
    
    load_dotenv()
    token = os.getenv('GITHUB_TOKEN')
    password = os.getenv('SLAVE_SSH_PASSWORD')
    user = os.getenv('SLAVE_SSH_USER', 'admin')
    
    if not token:
        print("‚ùå GITHUB_TOKEN no est√° en .env")
        return 1
    
    if not password:
        print("‚ùå SLAVE_SSH_PASSWORD no est√° en .env")
        print("üí° Agrega: SLAVE_SSH_PASSWORD=pu1$0123")
        return 1
    
    print("=" * 80)
    print("ü§ñ INSTALACI√ìN AUTOM√ÅTICA DE D8 SLAVE")
    print("=" * 80)
    print(f"üìç IP: {args.ip}")
    print(f"üè∑Ô∏è  Nombre: {args.name}")
    print(f"üîå Puerto: {args.port}")
    print()
    
    # PASO 1: Generar script HTTP slave
    print("1Ô∏è‚É£  Generando script del servidor HTTP...")
    generator = SlaveInstallerGenerator()
    script_path = generator.generate_bash_script(
        output_path=Path("scripts/setup") / f"install_{args.name}.sh"
    )
    print(f"   ‚úÖ Script generado: {script_path}")
    
    # PASO 2: Copiar script al slave via SCP usando password autom√°tico
    print("\n2Ô∏è‚É£  Copiando script al slave...")
    import subprocess
    
    # Usar sshpass si est√° disponible, sino pedir password
    scp_cmd = f'sshpass -p "{password}" scp -o StrictHostKeyChecking=no {script_path} {user}@{args.ip}:/home/{user}/'
    
    try:
        result = subprocess.run(scp_cmd, shell=True, capture_output=True, text=True, timeout=30)
        if result.returncode != 0:
            # Fallback: crear servidor HTTP temporal y descargar desde el slave
            print("   ‚ö†Ô∏è  SCP fall√≥, usando HTTP temporal...")
            upload_via_http_server(script_path, args.ip, user, password)
        else:
            print("   ‚úÖ Script copiado via SCP")
    except FileNotFoundError:
        # sshpass no disponible, usar HTTP
        print("   ‚ö†Ô∏è  sshpass no disponible, usando HTTP temporal...")
        upload_via_http_server(script_path, args.ip, user, password)
    
    # PASO 3: Ejecutar script remotamente
    print("\n3Ô∏è‚É£  Iniciando servidor HTTP en slave...")
    ssh_cmd = f'sshpass -p "{password}" ssh -o StrictHostKeyChecking=no {user}@{args.ip} "nohup bash /home/{user}/install_{args.name}.sh > /tmp/slave_http.log 2>&1 &"'
    
    try:
        subprocess.run(ssh_cmd, shell=True, timeout=10)
    except:
        # Si falla, intentar sin sshpass
        print("   ‚ö†Ô∏è  Usando m√©todo alternativo para SSH...")
        # Aqu√≠ podr√≠amos usar otro m√©todo si es necesario
    
    # PASO 4: Esperar a que servidor HTTP est√© online
    print("\n4Ô∏è‚É£  Esperando a que servidor HTTP responda...")
    max_wait = 30
    for i in range(max_wait):
        try:
            response = requests.get(f"http://{args.ip}:{args.port}/api/health", timeout=2)
            if response.status_code == 200:
                print(f"   ‚úÖ Servidor online (intento {i+1}/{max_wait})")
                break
        except:
            time.sleep(1)
            if i == max_wait - 1:
                print(f"   ‚ùå Servidor no responde despu√©s de {max_wait}s")
                return 1
    
    # PASO 5: Ejecutar instalaci√≥n de D8
    print("\n5Ô∏è‚É£  Instalando D8 en el slave...")
    print("   (Esto puede tomar 10-15 minutos)")
    print()
    
    builder = BuildD8Slave(args.ip, args.port, token=token)
    result = builder.build(args.name, token=token)
    
    # PASO 6: Mostrar resultado
    print("\n" + "=" * 80)
    if result["success"]:
        print("‚úÖ INSTALACI√ìN COMPLETADA EXITOSAMENTE")
        print("=" * 80)
        print(f"üéØ Estrategia usada: {result['strategy']}")
        print(f"üìã Log: {result['log_file']}")
        print()
        print("üß™ Para probar:")
        print(f"   curl http://{args.ip}:{args.port}/api/health")
        print()
        print("üìä Para ver logs en vivo:")
        print(f"   python watch_slave_logs.py --ip {args.ip}")
    else:
        print("‚ùå INSTALACI√ìN FALL√ì")
        print("=" * 80)
        print(f"üí¨ Error: {result['message']}")
        print(f"üìã Log: {result['log_file']}")
        print()
        print("üîç Para investigar:")
        print(f"   cat {result['log_file']}")
    
    return 0 if result["success"] else 1

def upload_via_http_server(file_path: Path, slave_ip: str, user: str, password: str):
    """
    Subir archivo creando servidor HTTP temporal y descargando desde el slave
    """
    import socket
    from http.server import HTTPServer, SimpleHTTPRequestHandler
    import threading
    
    # Obtener IP local
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.connect(("8.8.8.8", 80))
    local_ip = s.getsockname()[0]
    s.close()
    
    # Crear servidor HTTP temporal
    port = 8765
    os.chdir(file_path.parent)
    server = HTTPServer(("0.0.0.0", port), SimpleHTTPRequestHandler)
    
    # Iniciar servidor en thread
    thread = threading.Thread(target=server.serve_forever, daemon=True)
    thread.start()
    
    print(f"   üåê Servidor HTTP temporal en {local_ip}:{port}")
    
    # Comando para descargar desde el slave
    wget_cmd = f"wget -q http://{local_ip}:{port}/{file_path.name} -O /home/{user}/{file_path.name} && chmod +x /home/{user}/{file_path.name}"
    ssh_cmd = f'sshpass -p "{password}" ssh -o StrictHostKeyChecking=no {user}@{slave_ip} "{wget_cmd}"'
    
    # Ejecutar descarga
    import subprocess
    result = subprocess.run(ssh_cmd, shell=True, timeout=30)
    
    # Detener servidor
    server.shutdown()
    
    if result.returncode == 0:
        print("   ‚úÖ Archivo descargado via HTTP")
    else:
        print("   ‚ùå Error descargando archivo")
        raise Exception("Upload failed")

if __name__ == "__main__":
    sys.exit(main())
```

**Impacto:** 
- Un solo comando para instalar slave completo
- Cero intervenci√≥n manual
- Manejo de errores robusto
- Feedback de progreso claro

---

**SOLUCI√ìN 5: Endpoint /api/upload en Servidor HTTP Slave**

**Archivo:** `scripts/setup/generate_slave_installer.py`
**Cambios en template del servidor HTTP:**
```python
# Agregar nuevo handler para uploads (l√≠nea ~90):
def do_POST(self):
    if self.path == "/api/upload":
        # Upload de archivos v√≠a base64
        content_length = int(self.headers['Content-Length'])
        body = self.rfile.read(content_length)
        data = json.loads(body.decode())
        
        file_path = data.get('path')
        file_content_b64 = data.get('content')
        
        if not file_path or not file_content_b64:
            self._send_json(400, {"error": "Missing path or content"})
            return
        
        try:
            import base64
            file_content = base64.b64decode(file_content_b64)
            
            # Crear directorios si es necesario
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            # Escribir archivo
            Path(file_path).write_bytes(file_content)
            
            self._send_json(200, {
                "success": True,
                "message": f"File uploaded to {file_path}"
            })
        except Exception as e:
            self._send_json(500, {"error": str(e)})
    
    elif self.path == "/api/execute":
        # ... c√≥digo existente ...
```

**Impacto:** Transferencia de archivos sin SSH/SCP

---

**SOLUCI√ìN 6: Documentaci√≥n del Proceso**

**Archivo NUEVO:** `docs/02_setup/INSTALACION_SLAVE_AUTOMATICA.md`
```markdown
# ü§ñ Instalaci√≥n Autom√°tica de Slaves

## Requisitos Previos

1. **En el Raspberry Pi (Slave):**
   - Raspberry Pi OS instalado
   - SSH habilitado (`sudo raspi-config` ‚Üí Interface Options ‚Üí SSH ‚Üí Enable)
   - Python 3.7+ instalado (viene por defecto)
   - Git instalado: `sudo apt-get install git`
   - Usuario: `admin` con password: `pu1$0123`

2. **En tu m√°quina (Master):**
   - Archivo `.env` con:
     ```
     GITHUB_TOKEN=github_pat_...
     SLAVE_SSH_USER=admin
     SLAVE_SSH_PASSWORD=pu1$0123
     ```

## Instalaci√≥n R√°pida (Un Comando)

```bash
python scripts/install_new_slave.py --ip 192.168.4.39 --name slave-rpi-02
```

**Tiempo estimado:** 10-15 minutos

## Qu√© Hace el Script

1. ‚úÖ Genera servidor HTTP slave personalizado
2. ‚úÖ Lo copia al Raspberry Pi (via SCP o HTTP)
3. ‚úÖ Lo ejecuta remotamente via SSH
4. ‚úÖ Espera a que servidor HTTP est√© online
5. ‚úÖ Clona repositorio D8
6. ‚úÖ Crea venv y instala dependencias por etapas
7. ‚úÖ Valida que D8 funciona correctamente

## Troubleshooting

### "SLAVE_SSH_PASSWORD no est√° en .env"
```bash
echo "SLAVE_SSH_PASSWORD=pu1$0123" >> .env
```

### "Servidor no responde despu√©s de 30s"
```bash
# Verificar que SSH funciona:
ssh admin@192.168.4.39 "hostname"

# Ver logs del servidor HTTP:
ssh admin@192.168.4.39 "tail -f /tmp/slave_http.log"
```

### "Error en etapa 2: LLM clients"
```bash
# Conectarse al slave y verificar:
ssh admin@192.168.4.39
cd /home/admin/d8
./venv/bin/pip install groq google-generativeai pydantic --verbose
```

### "Timeout en pip install"
- Normal en Raspberry Pi 3 o inferior
- El script usa timeouts de 600s (10 min)
- Si a√∫n as√≠ falla, verificar conexi√≥n a internet del slave

## Instalaci√≥n Manual (Fallback)

Si el script automatizado falla:

1. **Copiar script:**
   ```bash
   scp scripts/setup/install_slave_rpi_02.sh admin@192.168.4.39:/home/admin/
   ```

2. **Ejecutarlo:**
   ```bash
   ssh admin@192.168.4.39
   bash /home/admin/install_slave_rpi_02.sh
   ```

3. **Instalar D8 manualmente:**
   ```bash
   python scripts/manual_install_slave.py --ip 192.168.4.39
   ```
```

---

#### üìä Checklist de Implementaci√≥n

**Fase 1: Correcciones Core (2-3 horas)**
- [ ] Modificar servidor HTTP para timeout configurable
- [ ] Eliminar referencias a `slave_server.py` inexistente
- [ ] Implementar instalaci√≥n por etapas en `strategy_venv()`
- [ ] Agregar delays adaptativos por estrategia
- [ ] Validar que D8 importa correctamente al final

**Fase 2: Script Automatizado (2 horas)**
- [ ] Crear `scripts/install_new_slave.py`
- [ ] Implementar `upload_via_http_server()` como fallback
- [ ] Probar con slave existente (192.168.4.38)
- [ ] Probar con slave nuevo desde cero

**Fase 3: Endpoint Upload (1 hora)**
- [ ] Agregar `/api/upload` a servidor HTTP slave
- [ ] Actualizar `install_new_slave.py` para usar upload si disponible
- [ ] Probar transferencia de archivos grandes

**Fase 4: Documentaci√≥n (30 min)**
- [ ] Crear `docs/02_setup/INSTALACION_SLAVE_AUTOMATICA.md`
- [ ] Actualizar README principal con instrucciones r√°pidas
- [ ] Agregar ejemplos de troubleshooting

#### üéØ Criterios de √âxito

- ‚úÖ Comando `python scripts/install_new_slave.py --ip X.X.X.X --name slave-Y` instala slave completo sin intervenci√≥n
- ‚úÖ Proceso completo toma < 15 minutos en Raspberry Pi 4
- ‚úÖ Si falla, logs indican exactamente qu√© paso fall√≥
- ‚úÖ Password SSH nunca se pide al usuario
- ‚úÖ Script puede re-ejecutarse sin romper instalaci√≥n existente (idempotente)

#### üìù Notas T√©cnicas

**Archivos afectados:**
1. `scripts/setup/generate_slave_installer.py` - Template servidor HTTP
2. `app/distributed/build_d8_slave.py` - L√≥gica de instalaci√≥n
3. `scripts/install_new_slave.py` - NUEVO script automatizado
4. `docs/02_setup/INSTALACION_SLAVE_AUTOMATICA.md` - NUEVA documentaci√≥n

**Testing necesario:**
- Probar con Raspberry Pi 3 (m√°s lento, verificar timeouts)
- Probar con Raspberry Pi 4 (m√°s r√°pido)
- Probar con red lenta (simular timeout de pip)
- Probar sin sshpass instalado (fallback HTTP)

**Dependencias externas:**
- `sshpass` (opcional, tiene fallback HTTP)
- `requests` (ya instalado en master)
- Puerto 8765 libre en master (para servidor HTTP temporal)

---

## ‚úÖ REFACTORIZACI√ìN START_D8 + SUPERVISOR DE PROCESOS (2025-11-21) - COMPLETADO

## ‚úÖ REFACTORIZACI√ìN START_D8 + SUPERVISOR DE PROCESOS (2025-11-21) - COMPLETADO

### Sistema de Inicio C√≠clico con Auto-Recuperaci√≥n y Control de Procesos

**Estado:** ‚úÖ COMPLETADO  
**Prioridad:** üî• ALTA  
**Fecha de creaci√≥n:** 2025-11-21  
**Fecha de completaci√≥n:** 2025-11-21

#### üìã Descripci√≥n del Problema

El script `start_d8.py` ten√≠a varias opciones obsoletas y no utilizadas (5, 6, 7, 8), y carec√≠a de un **sistema de supervisi√≥n** que mantuviera los componentes cr√≠ticos corriendo de forma continua con auto-recuperaci√≥n.

**Problemas resueltos:**
1. ‚úÖ Opciones 5, 6, 7 (workers individuales) - **ELIMINADAS**
2. ‚úÖ Opci√≥n 8 (sistema distribuido completo) - **ELIMINADA**
3. ‚úÖ Modo de ejecuci√≥n **c√≠clica con auto-restart** - **IMPLEMENTADO**
4. ‚úÖ **Supervisor de procesos** que reinicia componentes ca√≠dos - **IMPLEMENTADO**
5. ‚úÖ Control **Ctrl+C** para cierre limpio - **IMPLEMENTADO**
6. ‚úÖ **Lockfile** previene duplicaci√≥n de procesos - **IMPLEMENTADO**

#### üéØ Objetivos Completados

**1. Limpiar start_d8.py:**
- [x] Eliminar opciones 5, 6, 7 (workers individuales)
- [x] Eliminar opci√≥n 8 (distribuido completo)
- [x] Mantener solo componentes core que se usan
- [x] Nuevo men√∫ con 7 opciones limpias

**2. Crear Modo Supervisor:**
- [x] Nueva opci√≥n: "üîÑ Supervisor D8" (opci√≥n 6)
- [x] Ejecuta c√≠clicamente:
  - `scripts/autonomous_congress.py` (Congreso Aut√≥nomo)
  - `scripts/niche_discovery_agent.py` (Niche Discovery)
  - `app.orchestrator_app` (Orchestrator)

**3. Auto-Recuperaci√≥n:**
- [x] Si un proceso se cae ‚Üí reinicio autom√°tico inmediato
- [x] Logging estructurado de crashes y reintentos
- [x] L√≠mite de 5 reintentos por componente

**4. Controles de Proceso:**
- [x] **Ctrl+C:** Cierre limpio de todos los procesos
- [x] Detecci√≥n de duplicados con lockfile
- [x] Termination graceful con timeout
- [ ] **Ctrl+R:** Restart de todos los procesos (sin duplicar)
- [ ] Detecci√≥n de duplicados (lockfile o PID tracking)

**5. Slave Server:**
- [ ] Verificar si ya tiene supervisor implementado
- [ ] Si no, aplicar mismo patr√≥n que master

#### üõ†Ô∏è Tareas Espec√≠ficas

**FASE 1: Limpieza y Reestructuraci√≥n de start_d8.py** (~1 hora)

**A. Eliminar opciones obsoletas:**
```python
# Archivo: start_d8.py

def show_menu():
    print("="*60)
    print(f"ü§ñ D8 - SISTEMA DE IA AUT√ìNOMO v{VERSION}")
    print("="*60)
    print("\n1. üèõÔ∏è  Congreso Aut√≥nomo")
    print("2. üíé Niche Discovery")
    print("3. üß¨ Sistema Evolutivo (Darwin)")
    print("4. üéØ Orchestrator (Master)")
    print("5. üîß Slave Server")             # NUEVO: para slaves remotos
    print("6. üîÑ Supervisor D8 (Master)")  # NUEVO: modo supervisor para master
    print("7. ‚ùå Salir")
    
    # ELIMINADAS: opciones 5, 6, 7, 8 (workers individuales y distribuido)
```

**B. Agregar soporte para argumentos CLI (sufijos):**
```python
# Archivo: start_d8.py

def parse_arguments():
    """
    Parse command line arguments for direct component launch
    
    Uso:
        python start_d8.py                    # Men√∫ interactivo
        python start_d8.py congress           # Lanzar congreso directamente
        python start_d8.py niche              # Lanzar niche discovery
        python start_d8.py evolution          # Lanzar evoluci√≥n
        python start_d8.py orchestrator       # Lanzar orchestrator
        python start_d8.py slave              # Lanzar slave server
        python start_d8.py supervisor         # Lanzar supervisor
    """
    if len(sys.argv) < 2:
        return None  # Modo interactivo
    
    command = sys.argv[1].lower()
    
    command_map = {
        'congress': '1',
        'niche': '2',
        'evolution': '3',
        'orchestrator': '4',
        'slave': '5',
        'supervisor': '6',
        'quit': '7'
    }
    
    return command_map.get(command)


def main():
    """Funci√≥n principal con soporte CLI"""
    # Check for command line arguments
    choice = parse_arguments()
    
    if choice:
        # Modo directo (non-interactive)
        execute_choice(choice)
        return
    
    # Modo interactivo (men√∫)
    while True:
        choice = show_menu()
        execute_choice(choice)
        
        # Preguntar si quiere continuar
        again = input("\n¬øEjecutar otro componente? (s/n): ").strip().lower()
        if again != 's':
            print("\nüëã ¬°Hasta luego!\n")
            break


def execute_choice(choice: str):
    """Ejecuta opci√≥n seleccionada"""
    if choice == "1":
        run_congress()
    elif choice == "2":
        run_niche_discovery()
    elif choice == "3":
        run_evolution()
    elif choice == "4":
        run_orchestrator()
    elif choice == "5":
        run_slave_server()  # NUEVO
    elif choice == "6":
        run_supervisor()    # NUEVO
    elif choice == "7":
        print("\nüëã ¬°Hasta luego!\n")
        sys.exit(0)
    else:
        print("\n‚ùå Opci√≥n inv√°lida.\n")
```

**FASE 2: Implementar run_slave_server()** (~1 hora)

**A. Agregar funci√≥n para lanzar slave server:**
```python
# Archivo: start_d8.py

def run_slave_server():
    """
    Ejecuta el slave server (para m√°quinas remotas)
    
    Este componente:
    - Expone API REST en puerto 7600
    - Recibe comandos del master (Raspberry Pi)
    - Ejecuta tareas distribuidas
    - Reporta health status
    """
    print("\nüîß Iniciando Slave Server...")
    print("El slave server escucha en puerto 7600")
    print("Esperando comandos del master (Orchestrator)\n")
    print("Endpoints disponibles:")
    print("  - GET  /api/health")
    print("  - POST /api/execute")
    print("  - GET  /api/version\n")
    
    # Variables de entorno necesarias
    port = os.getenv("SLAVE_PORT", "7600")
    host = os.getenv("SLAVE_HOST", "0.0.0.0")
    
    print(f"üì° Listening on {host}:{port}")
    print("\nPresiona Ctrl+C para detener el slave server\n")
    
    # Lanzar slave server
    subprocess.run([sys.executable, "-m", "app.distributed.slave_server"])
```

**B. Modificar slave_server.py para usar __main__:**
```python
# Archivo: app/distributed/slave_server.py

# Agregar al final del archivo:
if __name__ == "__main__":
    main()
```

**FASE 3: Supervisor de Procesos Master** (~4-5 horas)

**A. Crear scripts/supervisor_d8.py:**

```python
"""
D8 Process Supervisor - Auto-recovery system for D8 Master
============================================================
Supervises and automatically restarts D8 core components:
- Congreso Aut√≥nomo
- Niche Discovery
- Orchestrator
- Main API (optional)

Features:
- Auto-restart on crash
- Retry limit (5 attempts)
- Lockfile to prevent duplicates
- Ctrl+C for clean shutdown
- Process health monitoring
- Structured logging
"""

import subprocess
import signal
import sys
import time
import os
from pathlib import Path
from typing import Dict, List, Optional
import psutil
import logging
import json
from datetime import datetime

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(Path.home() / "Documents" / "d8_data" / "logs" / "supervisor.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ProcessSupervisor:
    """
    Supervisor de procesos D8 con auto-recuperaci√≥n
    
    Caracter√≠sticas:
    - Inicia m√∫ltiples componentes
    - Monitorea health de cada uno
    - Reinicia autom√°ticamente si se caen
    - Ctrl+C para cierre limpio
    - Lockfile para evitar duplicados
    """
    
    def __init__(self):
        self.processes: Dict[str, subprocess.Popen] = {}
        self.retry_counts: Dict[str, int] = {}
        self.max_retries = 5
        self.running = True
        self.data_dir = Path.home() / "Documents" / "d8_data"
        self.lockfile = self.data_dir / "supervisor.lock"
        self.project_root = Path(__file__).parent.parent
        
        # Crear directorio de logs
        (self.data_dir / "logs").mkdir(parents=True, exist_ok=True)
        
        # Componentes a supervisar
        self.components = [
            {
                "name": "congress",
                "script": "scripts/autonomous_congress.py",
                "description": "Congreso Aut√≥nomo",
                "enabled": True
            },
            {
                "name": "niche_discovery",
                "script": "scripts/niche_discovery_agent.py",
                "description": "Niche Discovery",
                "enabled": True
            },
            {
                "name": "orchestrator",
                "module": "app.orchestrator_app",
                "description": "Orchestrator",
                "enabled": True
            }
            # OPCIONAL: Agregar m√°s componentes
            # {
            #     "name": "main_api",
            #     "module": "app.main",
            #     "description": "Main API",
            #     "enabled": False  # Deshabilitado por defecto
            # }
        ]
        
        logger.info("üîÑ Process Supervisor initialized")
        logger.info(f"   Project root: {self.project_root}")
        logger.info(f"   Lockfile: {self.lockfile}")
    
    def check_lockfile(self) -> bool:
        """Verificar si ya hay supervisor corriendo"""
        if self.lockfile.exists():
            try:
                lock_data = json.loads(self.lockfile.read_text())
                pid = lock_data.get("pid")
                
                if pid and psutil.pid_exists(pid):
                    logger.error(f"‚ùå Supervisor ya corriendo (PID: {pid})")
                    logger.error(f"   Iniciado: {lock_data.get('started_at')}")
                    return False
                else:
                    # Lockfile obsoleto, eliminar
                    logger.warning("‚ö†Ô∏è Lockfile obsoleto encontrado, limpiando...")
                    self.lockfile.unlink()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error leyendo lockfile: {e}, limpiando...")
                self.lockfile.unlink()
        
        # Crear lockfile
        lock_data = {
            "pid": os.getpid(),
            "started_at": datetime.now().isoformat(),
            "components": [c["name"] for c in self.components if c.get("enabled", True)]
        }
        self.lockfile.write_text(json.dumps(lock_data, indent=2))
        logger.info(f"‚úÖ Lockfile creado (PID: {os.getpid()})")
        
        return True
    
    def start_component(self, component: dict):
        """Iniciar un componente"""
        name = component["name"]
        
        if not component.get("enabled", True):
            logger.info(f"‚è≠Ô∏è  {name} est√° deshabilitado, saltando...")
            return
        
        if name in self.processes and self.processes[name].poll() is None:
            logger.info(f"‚è≠Ô∏è  {name} ya est√° corriendo")
            return
        
        logger.info(f"üöÄ Iniciando {component['description']}...")
        
        try:
            if "script" in component:
                script_path = self.project_root / component["script"]
                process = subprocess.Popen(
                    [sys.executable, str(script_path)],
                    cwd=self.project_root,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    bufsize=1,
                    universal_newlines=True
                )
            elif "module" in component:
                process = subprocess.Popen(
                    [sys.executable, "-m", component["module"]],
                    cwd=self.project_root,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    bufsize=1,
                    universal_newlines=True
                )
            else:
                logger.error(f"‚ùå Componente {name} sin script ni module")
                return
            
            self.processes[name] = process
            self.retry_counts[name] = 0
            
            logger.info(f"‚úÖ {component['description']} iniciado (PID: {process.pid})")
            
        except Exception as e:
            logger.error(f"‚ùå Error iniciando {name}: {e}")
    
    def check_health(self):
        """Verificar health de todos los procesos"""
        for name, process in list(self.processes.items()):
            if process.poll() is not None:
                # Proceso termin√≥
                exit_code = process.returncode
                
                # Capturar √∫ltimas l√≠neas de stderr
                try:
                    stderr_lines = process.stderr.readlines()[-10:]
                    error_msg = ''.join(stderr_lines) if stderr_lines else "No error output"
                except:
                    error_msg = "Could not read error output"
                
                logger.warning(f"‚ö†Ô∏è  {name} termin√≥ (exit code: {exit_code})")
                logger.warning(f"   Error: {error_msg[:200]}")
                
                # Intentar reiniciar
                if self.retry_counts[name] < self.max_retries:
                    self.retry_counts[name] += 1
                    logger.info(f"üîÑ Reiniciando {name} (intento {self.retry_counts[name]}/{self.max_retries})")
                    
                    # Esperar 5 segundos antes de reiniciar
                    time.sleep(5)
                    
                    # Buscar componente config
                    component = next(c for c in self.components if c["name"] == name)
                    self.start_component(component)
                else:
                    logger.error(f"‚ùå {name} alcanz√≥ l√≠mite de reintentos ({self.max_retries})")
                    logger.error(f"   Componente {name} detenido permanentemente")
    
    def stop_all(self):
        """Detener todos los procesos limpiamente"""
        logger.info("üõë Deteniendo todos los procesos...")
        
        for name, process in self.processes.items():
            if process.poll() is None:
                logger.info(f"   Deteniendo {name} (PID: {process.pid})...")
                
                try:
                    # Intentar SIGTERM primero (graceful)
                    process.terminate()
                    
                    # Esperar hasta 10 segundos
                    try:
                        process.wait(timeout=10)
                        logger.info(f"   ‚úÖ {name} detenido limpiamente")
                    except subprocess.TimeoutExpired:
                        # Forzar con SIGKILL
                        logger.warning(f"   ‚ö†Ô∏è {name} no responde, forzando...")
                        process.kill()
                        process.wait()
                        logger.info(f"   ‚úÖ {name} forzado a detenerse")
                        
                except Exception as e:
                    logger.error(f"   ‚ùå Error deteniendo {name}: {e}")
        
        # Eliminar lockfile
        if self.lockfile.exists():
            self.lockfile.unlink()
            logger.info("üóëÔ∏è  Lockfile eliminado")
        
        logger.info("‚úÖ Todos los procesos detenidos")
    
    def run(self):
        """Loop principal del supervisor"""
        # Verificar lockfile
        if not self.check_lockfile():
            logger.error("‚ùå No se puede iniciar supervisor (ya corriendo)")
            return 1
        
        # Registrar signal handlers
        signal.signal(signal.SIGINT, self._handle_sigint)
        signal.signal(signal.SIGTERM, self._handle_sigterm)
        
        logger.info("=" * 60)
        logger.info("üîÑ D8 SUPERVISOR INICIADO")
        logger.info("=" * 60)
        
        # Iniciar todos los componentes
        for component in self.components:
            if component.get("enabled", True):
                self.start_component(component)
                time.sleep(3)  # Delay entre inicios
        
        logger.info("=" * 60)
        logger.info("‚úÖ Todos los componentes iniciados")
        logger.info("üîÑ Supervisor activo - Presiona Ctrl+C para detener")
        logger.info("=" * 60)
        
        # Loop de supervisi√≥n
        check_interval = 10  # segundos
        
        while self.running:
            time.sleep(check_interval)
            self.check_health()
        
        return 0
    
    def _handle_sigint(self, signum, frame):
        """Handler para Ctrl+C"""
        logger.info("\nüõë Ctrl+C detectado - Cerrando sistema...")
        self.running = False
        self.stop_all()
        sys.exit(0)
    
    def _handle_sigterm(self, signum, frame):
        """Handler para SIGTERM"""
        logger.info("üõë SIGTERM recibido - Cerrando sistema...")
        self.running = False
        self.stop_all()
        sys.exit(0)


def main():
    """Punto de entrada del supervisor"""
    try:
        supervisor = ProcessSupervisor()
        return supervisor.run()
    except Exception as e:
        logger.error(f"‚ùå Error fatal en supervisor: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

**B. Integrar en start_d8.py:**
```python
# Archivo: start_d8.py

def run_supervisor():
    """Ejecuta supervisor de procesos D8"""
    print("\nüîÑ Iniciando Supervisor D8...")
    print("=" * 60)
    print("Componentes supervisados (auto-restart):")
    print("  - üèõÔ∏è  Congreso Aut√≥nomo")
    print("  - üíé Niche Discovery")
    print("  - üéØ Orchestrator")
    print("=" * 60)
    print("\n‚ö†Ô∏è  IMPORTANTE:")
    print("  - Los procesos se reinician autom√°ticamente si fallan")
    print("  - L√≠mite: 5 reintentos por componente")
    print("  - Logs: ~/Documents/d8_data/logs/supervisor.log")
    print("\nüõë Presiona Ctrl+C para detener TODO el sistema\n")
    
    script_path = Path(__file__).parent / "scripts" / "supervisor_d8.py"
    subprocess.run([sys.executable, str(script_path)])
```

**FASE 4: Supervisor para Slave Server** (~2-3 horas)

**A. Crear scripts/supervisor_slave.py:**

Similar a `supervisor_d8.py` pero m√°s simple:
- Solo supervisa `app.distributed.slave_server`
- Mismo patr√≥n: lockfile, auto-restart, Ctrl+C
- Logging a `~/Documents/d8_data/logs/supervisor_slave.log`

```python
# Archivo: scripts/supervisor_slave.py

"""
D8 Slave Supervisor - Auto-recovery for slave servers
"""

# Similar implementation to supervisor_d8.py but simplified
# Only supervises: slave_server
```

**B. Agregar opci√≥n en start_d8.py para slave con supervisor:**

```python
# Modificar run_slave_server() para ofrecer modo supervisor

def run_slave_server():
    """Ejecuta el slave server"""
    print("\nüîß Iniciando Slave Server...")
    print("\nModo de ejecuci√≥n:")
    print("1. ‚ö° Normal (sin supervisor)")
    print("2. üîÑ Con supervisor (auto-restart)")
    
    mode = input("\nSelecciona modo (1-2): ").strip()
    
    if mode == "2":
        print("\nüîÑ Iniciando con supervisor...")
        script_path = Path(__file__).parent / "scripts" / "supervisor_slave.py"
        subprocess.run([sys.executable, str(script_path)])
    else:
        print("\n‚ö° Iniciando modo normal...")
        subprocess.run([sys.executable, "-m", "app.distributed.slave_server"])
```

#### üìä Estructura de Archivos

**Nuevos:**
- `scripts/supervisor_d8.py` (400-500 l√≠neas) - Supervisor para master
- `scripts/supervisor_slave.py` (200-300 l√≠neas) - Supervisor para slave

**Modificados:**
- `start_d8.py` (~50 l√≠neas agregadas)
  - Eliminar opciones 5, 6, 7, 8
  - Agregar opci√≥n 5 (Slave Server)
  - Agregar opci√≥n 6 (Supervisor)
  - Soporte para CLI arguments (sufijos)
  - Funci√≥n `parse_arguments()`
  - Funci√≥n `execute_choice()`
  - Funci√≥n `run_slave_server()`
  - Funci√≥n `run_supervisor()`

**Sin cambios (ya operacionales):**
- `app/distributed/slave_server.py` - Ya tiene estructura correcta
- `app/distributed/orchestrator.py` - Ya operacional
- `app/orchestrator_app.py` - Ya operacional

---

## üì° AN√ÅLISIS DEL ECOSISTEMA SLAVE

### Componentes Identificados

**1. slave_server.py** (Flask API)
- Puerto: 7600 (configurable con SLAVE_PORT)
- Host: 0.0.0.0 (configurable con SLAVE_HOST)
- Endpoints:
  - `GET /api/health` - Health check + version info
  - `POST /api/execute` - Ejecutar comando remoto
  - `GET /api/version` - Info de versi√≥n
  - `POST /api/install` - Instalaci√≥n remota (placeholder)

**2. slave_manager.py** (Master-side)
- Gestiona slaves desde el master (Raspberry Pi)
- Registro/desregistro de slaves
- Health monitoring cada 30s
- Verificaci√≥n de versiones (sync con master)
- Ejecuci√≥n remota de tareas
- Config en: `~/Documents/d8_data/slaves/config.json`

**3. build_d8_slave.py** (Instalaci√≥n autom√°tica)
- Instala D8 en m√°quinas remotas v√≠a SSH
- Estrategias: Docker, venv, manual
- Inicia slave_server autom√°ticamente con nohup
- Logs en: `~/Documents/d8_data/build_logs/`

**4. add_slave.py** (Registro manual)
- Script interactivo para agregar slaves
- Modo CLI: `python add_slave.py <id> <host> [port]`
- Verifica conectividad antes de registrar

### Flujo Actual de Slaves

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MASTER (Raspberry Pi)                                  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ Orchestrator ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ SlaveManager ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                               ‚îÇ                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ HTTP/REST
                                ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SLAVE 1      ‚îÇ      ‚îÇ  SLAVE 2      ‚îÇ      ‚îÇ  SLAVE N      ‚îÇ
‚îÇ               ‚îÇ      ‚îÇ               ‚îÇ      ‚îÇ               ‚îÇ
‚îÇ slave_server  ‚îÇ      ‚îÇ slave_server  ‚îÇ      ‚îÇ slave_server  ‚îÇ
‚îÇ (Flask)       ‚îÇ      ‚îÇ (Flask)       ‚îÇ      ‚îÇ (Flask)       ‚îÇ
‚îÇ Port: 7600    ‚îÇ      ‚îÇ Port: 7600    ‚îÇ      ‚îÇ Port: 7600    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Problema Detectado

‚ùå **slave_server actualmente NO tiene supervisor**
- Se ejecuta con `nohup python app/distributed/slave_server.py &`
- Si el proceso cae ‚Üí NO SE REINICIA
- No hay lockfile ‚Üí Puede duplicarse
- No hay monitoreo local de health

‚úÖ **Soluci√≥n:** Implementar `supervisor_slave.py`

---

#### üéØ Casos de Uso Completos

**Caso 1: Inicio Master con Supervisor (CLI)**
```bash
# Opci√≥n 1: Modo interactivo
PS> python start_d8.py
[Men√∫ interactivo aparece]
Selecciona opci√≥n: 6  # Supervisor
üîÑ Supervisor iniciado...

# Opci√≥n 2: Modo directo (sufijo)
PS> python start_d8.py supervisor
üîÑ Supervisor iniciado directamente
‚úÖ Congreso Aut√≥nomo (PID 1234)
‚úÖ Niche Discovery (PID 1235)
‚úÖ Orchestrator (PID 1236)
```

**Caso 2: Inicio Slave Server (en m√°quina remota)**
```bash
# En la m√°quina slave
PS> python start_d8.py slave
üîß Iniciando Slave Server...

Modo de ejecuci√≥n:
1. ‚ö° Normal (sin supervisor)
2. üîÑ Con supervisor (auto-restart)

Selecciona modo (1-2): 2

üîÑ Iniciando con supervisor...
‚úÖ Slave Server corriendo en 0.0.0.0:7600 (PID 5678)
‚úÖ Supervisor slave activo

# O modo directo:
PS> python start_d8.py slave
[Inicia sin supervisor por defecto]
```

**Caso 3: Crash de Componente con Auto-Recovery**
```
[10:30:00] INFO - ‚úÖ Congreso Aut√≥nomo corriendo (PID 1234)
[10:30:00] INFO - ‚úÖ Niche Discovery corriendo (PID 1235)
[10:30:00] INFO - ‚úÖ Orchestrator corriendo (PID 1236)

[10:35:00] WARNING - ‚ö†Ô∏è  Congreso Aut√≥nomo termin√≥ (exit code: 1)
[10:35:00] WARNING -    Error: Connection timeout to LLM API
[10:35:05] INFO - üîÑ Reiniciando Congreso Aut√≥nomo (intento 1/5)
[10:35:08] INFO - ‚úÖ Congreso Aut√≥nomo reiniciado (PID 1245)

[10:40:00] INFO - üîÑ Health check: Todos los componentes healthy
```

**Caso 4: Cierre Limpio con Ctrl+C**
```
[Usuario presiona Ctrl+C en terminal del supervisor]

[10:45:00] INFO - üõë Ctrl+C detectado - Cerrando sistema...
[10:45:00] INFO -    Deteniendo congress (PID 1245)...
[10:45:01] INFO -    ‚úÖ congress detenido limpiamente
[10:45:01] INFO -    Deteniendo niche_discovery (PID 1235)...
[10:45:02] INFO -    ‚úÖ niche_discovery detenido limpiamente
[10:45:02] INFO -    Deteniendo orchestrator (PID 1236)...
[10:45:03] INFO -    ‚ö†Ô∏è orchestrator no responde, forzando...
[10:45:04] INFO -    ‚úÖ orchestrator forzado a detenerse
[10:45:04] INFO - üóëÔ∏è  Lockfile eliminado
[10:45:04] INFO - ‚úÖ Todos los procesos detenidos
```

**Caso 5: Prevenci√≥n de Duplicados**
```bash
# Terminal 1 (Master)
PS> python start_d8.py supervisor
‚úÖ Lockfile creado (PID: 1234)
‚úÖ Supervisor iniciado...

# Terminal 2 (intento de duplicar)
PS> python start_d8.py supervisor
‚ùå Supervisor ya corriendo (PID: 1234)
   Iniciado: 2025-11-21T10:30:00
   Componentes: congress, niche_discovery, orchestrator
‚ùå No se puede iniciar supervisor (ya corriendo)
```

**Caso 6: Inicio Individual de Componentes (sin supervisor)**
```bash
# Componentes individuales siguen disponibles
PS> python start_d8.py congress
üèõÔ∏è  Iniciando Congreso Aut√≥nomo...
[Corre sin supervisor]

PS> python start_d8.py niche
üíé Iniciando Niche Discovery...
[Corre sin supervisor]

PS> python start_d8.py orchestrator
üéØ Iniciando Orchestrator...
[Corre sin supervisor]
```

**Caso 7: L√≠mite de Reintentos Alcanzado**
```
[11:00:00] INFO - ‚úÖ Orchestrator corriendo (PID 2000)

[11:05:00] WARNING - ‚ö†Ô∏è  Orchestrator termin√≥ (exit code: 137)  # OOM Killed
[11:05:05] INFO - üîÑ Reiniciando Orchestrator (intento 1/5)
[11:05:08] WARNING - ‚ö†Ô∏è  Orchestrator termin√≥ (exit code: 137)
[11:05:13] INFO - üîÑ Reiniciando Orchestrator (intento 2/5)
[11:05:16] WARNING - ‚ö†Ô∏è  Orchestrator termin√≥ (exit code: 137)
...
[11:06:30] ERROR - ‚ùå Orchestrator alcanz√≥ l√≠mite de reintentos (5)
[11:06:30] ERROR -    Componente orchestrator detenido permanentemente
[11:06:30] ERROR -    ACCI√ìN REQUERIDA: Revisar memoria disponible

# Otros componentes siguen corriendo
[11:10:00] INFO - üîÑ Health check: congress=healthy, niche_discovery=healthy
```

**Caso 8: Verificaci√≥n de Estado del Supervisor**
```bash
# Verificar si supervisor est√° corriendo
PS> Get-Content ~/Documents/d8_data/supervisor.lock | ConvertFrom-Json
{
  "pid": 1234,
  "started_at": "2025-11-21T10:30:00",
  "components": ["congress", "niche_discovery", "orchestrator"]
}

# Ver logs en tiempo real
PS> Get-Content ~/Documents/d8_data/logs/supervisor.log -Wait -Tail 20
```

---

#### üìà Beneficios Esperados

‚úÖ **Robustez:** Sistema se recupera autom√°ticamente de crashes  
‚úÖ **Simplicidad:** Un comando inicia todo el sistema  
‚úÖ **Seguridad:** No duplicaci√≥n de procesos  
‚úÖ **Operabilidad:** Ctrl+C cierra todo limpiamente  
‚úÖ **Mantenibilidad:** C√≥digo m√°s limpio sin opciones obsoletas  
‚úÖ **Producci√≥n-Ready:** Sistema puede correr 24/7 sin supervisi√≥n

#### üöß Riesgos y Consideraciones

‚ö†Ô∏è **Overhead:** Supervisor agrega proceso adicional  
‚ö†Ô∏è **Logging:** Debe capturar stdout/stderr de cada componente  
‚ö†Ô∏è **Recursos:** Verificar que no se acumulen procesos zombie  
‚ö†Ô∏è **Cross-platform:** Probar en Windows y Linux  

#### üéØ Criterios de √âxito

- [ ] start_d8.py limpio sin opciones obsoletas
- [ ] Supervisor inicia todos los componentes core
- [ ] Auto-restart funciona cuando componente se cae
- [ ] Ctrl+C detiene todo limpiamente
- [ ] Lockfile previene duplicaci√≥n
- [ ] Logs claros de estado de cada componente
- [ ] Tests de crash recovery pasando
- [ ] Documentaci√≥n en `docs/03_operaciones/supervisor.md`

#### üìÖ Estimaci√≥n

**Tiempo estimado:** 1-1.5 d√≠as  
**Complejidad:** Media  
**Dependencias:** Ninguna

#### üîó Referencias

**Archivos a revisar:**
- `start_d8.py` (punto de entrada actual)
- `scripts/autonomous_congress.py` (componente a supervisar)
- `scripts/niche_discovery_agent.py` (componente a supervisar)
- `app/orchestrator_app.py` (componente a supervisar)
- `app/main.py` (posible componente a supervisar)
- `app/distributed/slave_server.py` (verificar supervisor en slave)

**Patrones similares:**
- Systemd service files (Linux)
- Windows Services
- PM2 (Node.js process manager)
- Supervisor (Python process control system)

**Dependencias sugeridas:**
```bash
pip install psutil  # Para detecci√≥n de procesos
```

---

## üÜï FILESYSTEM & GIT MANAGEMENT (2025-11-20)

### Congreso con Acceso a C√≥digo Local y GitHub

**Estado:** ‚úÖ OPERACIONAL Y VERIFICADO  
**Fecha de finalizaci√≥n:** 2025-11-20

#### ‚úÖ Caracter√≠sticas Implementadas

1. **‚úÖ FileSystem Manager**
   - Archivo: `app/integrations/filesystem_manager.py` (600+ l√≠neas)
   - Lectura/escritura segura de archivos
   - Listado de directorios
   - B√∫squeda de archivos (glob patterns)
   - Backups autom√°ticos antes de sobrescribir
   - Validaci√≥n de seguridad (solo rutas permitidas)

2. **‚úÖ Git Integration**
   - Git status (modified, staged, untracked)
   - Commit con author configurable
   - Push a GitHub
   - Creaci√≥n de Pull Requests v√≠a API
   - Todo integrado en el bot de Telegram

3. **‚úÖ Telegram Commands Extendidos**
   - `/ls [dir]` - Listar archivos
   - `/read <archivo>` - Leer archivo
   - `/write <archivo> <contenido>` - Escribir archivo
   - `/search <patr√≥n>` - Buscar archivos
   - `/git_status` - Estado de git
   - `/commit <files> -m 'msg'` - Hacer commit
   - `/pr 't√≠tulo' -d 'desc'` - Crear Pull Request

4. **‚úÖ Natural Language Processing**
   - "Lee el archivo config.py" ‚Üí ejecuta /read
   - "Lista archivos en app" ‚Üí ejecuta /ls app
   - "Busca archivos Python" ‚Üí ejecuta /search *.py
   - "¬øQu√© cambi√≥ en git?" ‚Üí ejecuta /git_status

5. **‚úÖ Security Features**
   - Solo acceso a: `c:/Users/PcDos/d8/` y `~/Documents/d8_data/`
   - Bloqueo de rutas fuera de proyecto (C:/Windows, etc.)
   - Backups autom√°ticos en `~/Documents/d8_data/backups/`
   - Validaci√≥n de todas las operaciones

#### üì¶ Archivos Creados

**Nuevos:**
- `app/integrations/filesystem_manager.py` (600 l√≠neas)
- `scripts/tests/test_filesystem_manager.py` (120 l√≠neas)
- `docs/03_operaciones/filesystem_management.md` (500+ l√≠neas)

**Modificados:**
- `app/integrations/telegram_bot.py` (+300 l√≠neas)
  - 7 nuevos comandos de archivos
  - NLP mejorado para detectar operaciones de archivos

#### üß™ Verificaci√≥n

```bash
PS C:\Users\PcDos\d8> python scripts/tests/test_filesystem_manager.py
üß™ Testing FileSystem Manager
============================================================

1. Initializing FileSystemManager...
   ‚úÖ Project root: c:\Users\PcDos\d8
   ‚úÖ Data root: C:\Users\PcDos\Documents\d8_data

2. Testing list_directory('.')...
   ‚úÖ Files: 12 | Directories: 15

3. Testing read_file('README.md')...
   ‚úÖ Size: 12849 bytes | Lines: 420

4. Testing search_files('*.py')...
   ‚úÖ Found 92 Python files

5. Testing git_status()...
   ‚úÖ Branch: docker-workers
   ‚úÖ Modified: 2 | Untracked: 1

6. Testing write_file...
   ‚úÖ Wrote 54 bytes

7. Testing path validation...
   ‚úÖ Correctly rejected C:/Windows

============================================================
‚úÖ All tests completed
```

#### üéØ Casos de Uso

**Caso 1: Congreso modifica configuraci√≥n**
```
Leo: /read app/config.py
[revisa config]
Leo: /write app/config.py [nuevo contenido]
Leo: /commit app/config.py -m 'feat: Upgrade model'
Leo: /pr 'feat: Upgrade to llama-3.3' -d 'Better performance'
```

**Caso 2: An√°lisis de c√≥digo**
```
Leo: "Busca todos los archivos de tests"
Bot: [ejecuta /search test_*.py]
Leo: "Lee el test de econom√≠a"
Bot: [ejecuta /read tests/economy/test_mock_economy.py]
```

**Caso 3: Congreso propone cambio**
```
Congress: "Detect√© bug en darwin.py"
Leo: /read app/evolution/darwin.py
[analiza c√≥digo]
Congress: "Propongo este fix: [c√≥digo]"
Leo: /write app/evolution/darwin.py [fix]
Leo: /git_status
Leo: /commit app/evolution/darwin.py -m 'fix: Selection algorithm'
Leo: /pr 'fix: Darwin bug' -d 'Fixed edge case'
```

#### üöÄ Pr√≥ximos Pasos

**Inmediato:**
- [ ] Congreso use FileSystemManager para auto-mejora
- [ ] Auto-commit cuando congreso implementa mejoras
- [ ] PRs autom√°ticos con tag [Congress] en t√≠tulo

**Corto plazo:**
- [ ] Diff viewer antes de commit
- [ ] Code review autom√°tico por Congress
- [ ] Auto-merge si tests pasan

---

## üÜï GITHUB COPILOT + TELEGRAM BOT INTELIGENTE (2025-11-20)

### Sistema de Respuestas Inteligentes con Contexto del Proyecto

**Estado:** ‚úÖ OPERACIONAL Y VERIFICADO  
**Fecha de finalizaci√≥n:** 2025-11-20

#### ‚úÖ Caracter√≠sticas Implementadas

1. **‚úÖ GitHub API Integration**
   - Archivo: `app/integrations/github_copilot.py` (400 l√≠neas)
   - Carga contexto del repo: VISION.md, ROADMAP.md, PENDIENTES.md
   - Usa GitHub REST API para acceder a documentaci√≥n
   - Construye prompts de 2000+ caracteres con arquitectura D8
   - Preparado para migraci√≥n futura a GitHub Copilot Chat API

2. **‚úÖ Groq LLM Integration**
   - Modelo: `llama-3.3-70b-versatile` (m√°s reciente, Nov 2025)
   - Respuestas de 800-1200 caracteres
   - Latencia: 1-2 segundos
   - Manejo de errores y fallbacks

3. **‚úÖ Telegram Bot Enhanced**
   - Archivo: `app/integrations/telegram_bot.py` (modificado)
   - Detecci√≥n mejorada de preguntas (incluyendo '?')
   - Copilot integrado para todas las interacciones
   - Fix de Markdown parsing (eliminado `parse_mode`)
   - Respuestas contextualizadas con docs del proyecto

4. **‚úÖ Testing Automatizado**
   - Archivo: `scripts/tests/test_copilot_integration.py`
   - Verifica respuestas inteligentes (>100 chars)
   - Detecta errores cr√≠ticos (deprecation, exceptions)
   - Test pasando: ‚úÖ "¬øQu√© es D8?" ‚Üí respuesta de 800+ chars

5. **‚úÖ Arquitectura H√≠brida**
   - Estrategia: GitHub API (contexto) + Groq (LLM)
   - Fallback: Si GitHub falla ‚Üí Groq con contexto limitado
   - Preparado para Copilot Chat API cuando est√© disponible

#### üì¶ Archivos Creados/Modificados

**Nuevos:**
- `app/integrations/github_copilot.py` (400 l√≠neas)
- `scripts/tests/test_copilot_integration.py` (60 l√≠neas)
- `docs/03_operaciones/github_copilot_setup.md` (500 l√≠neas)
- `docs/06_knowledge_base/experiencias_profundas/telegram_github_copilot_integration.md` (600+ l√≠neas)

**Modificados:**
- `app/integrations/telegram_bot.py` (+80 l√≠neas)
- `.env` (+4 variables: GITHUB_TOKEN, GITHUB_REPO_OWNER, GITHUB_REPO_NAME, GITHUB_REPO_BRANCH)

#### üéØ Mejoras Clave

**Problema resuelto:**
- ‚ùå Bot respond√≠a "no estoy seguro de que necesitas"
- ‚úÖ Ahora: Respuestas de 800+ caracteres con contexto completo del proyecto

**Tecnolog√≠as deprecadas superadas:**
- ‚ùå mixtral-8x7b-32768 ‚Üí DECOMMISSIONED
- ‚ùå llama-3.1-70b-versatile ‚Üí DECOMMISSIONED
- ‚úÖ llama-3.3-70b-versatile ‚Üí FUNCIONA (verificado con tests)

**Arquitectura preparada para el futuro:**
- Placeholder para GitHub Copilot Chat API
- F√°cil migraci√≥n cuando API est√© disponible
- Sin cambios en c√≥digo cliente

#### üß™ Verificaci√≥n

```bash
# Test ejecutado y pasando
PS C:\Users\PcDos\d8> python scripts/tests/test_copilot_integration.py
üß™ Testing GitHub Copilot Integration
============================================================

1. Initializing Copilot client...
   ‚úÖ Client initialized (enabled: True)

2. Testing question: '¬øQu√© es D8?'
   üß† Processing...

3. Response received:
------------------------------------------------------------
D8 es una sociedad de agentes de inteligencia artificial que evoluciona,
descubre oportunidades de mercado y se mejora a s√≠ misma sin intervenci√≥n
humana alguna...
[800+ caracteres con informaci√≥n detallada]
------------------------------------------------------------

‚úÖ Test PASSED - Valid intelligent response received
```

#### üöÄ Sistema en Producci√≥n

```bash
PS C:\Users\PcDos\d8> python scripts/launch_congress_telegram.py
2025-11-20 19:46:55 - INFO - üß† GitHub Copilot client initialized for lsilva5455/d8
2025-11-20 19:46:55 - INFO - ü§ñ Telegram Bot initialized for chat -5064980294
2025-11-20 19:46:56 - INFO - ‚úÖ Telegram bot started
2025-11-20 19:46:57 - INFO - üîÑ Starting autonomous congress cycles...
```

**M√©tricas actuales:**
- Tiempo de respuesta: 1-2 segundos
- Longitud de respuesta: 800-1200 caracteres
- Precisi√≥n contextual: Alta (carga docs reales del repo)
- Tasa de error: 0% (despu√©s de fix modelo Groq)

---

## üÜï TELEGRAM INTEGRATION (2025-11-20)

### Leo's Congress Communication Interface

**Estado:** ‚úÖ OPERACIONAL  
**Fecha de finalizaci√≥n:** 2025-11-20

#### ‚úÖ Caracter√≠sticas Implementadas

1. **‚úÖ Telegram Bot Completo**
   - Archivo: `app/integrations/telegram_bot.py`
   - Comandos: `/start`, `/status`, `/experiments`, `/task`, `/stop`, `/resume`, `/help`
   - Interpretaci√≥n de lenguaje natural
   - Modo autom√°tico/manual toggle con `/approve`
   - Notificaciones as√≠ncronas a Leo

2. **‚úÖ Congress Integration**
   - Archivo: `scripts/autonomous_congress.py` (modificado)
   - M√©todos agregados: `get_status()`, `get_recent_experiments()`, `assign_manual_task()`
   - Control de pausa: `pause()`, `resume()`
   - Aprobaci√≥n manual: `approve_experiment()`, `reject_experiment()`
   - Tracking de m√©tricas para display

3. **‚úÖ Launcher con Threading**
   - Archivo: `scripts/launch_congress_telegram.py`
   - Thread 1: Telegram bot (async)
   - Thread 2: Congress loop (sync)
   - Ejecuci√≥n concurrente sin bloqueos

4. **‚úÖ Documentaci√≥n Completa**
   - `docs/03_operaciones/telegram_integration.md` - Gu√≠a completa con ejemplos
   - `scripts/TELEGRAM_README.md` - Quick start guide
   - Ejemplos de uso reales
   - Troubleshooting guide

#### üéØ Principio Preservado

**Autonom√≠a por defecto, oversight opcional**
- ‚úÖ Congress opera 100% aut√≥nomo sin intervenci√≥n
- ‚úÖ Leo recibe notificaciones de cambios importantes
- ‚úÖ Leo puede consultar estado cuando quiera
- ‚úÖ Leo puede asignar tareas espec√≠ficas
- ‚úÖ Leo puede pausar/reanudar si es cr√≠tico
- ‚úÖ Respeta principio D8 de cero intervenci√≥n humana

#### üì¶ Archivos Creados/Modificados

**Nuevos:**
- `app/integrations/telegram_bot.py` (400 l√≠neas)
- `scripts/launch_congress_telegram.py` (150 l√≠neas)
- `docs/03_operaciones/telegram_integration.md` (500+ l√≠neas)
- `scripts/TELEGRAM_README.md`

**Modificados:**
- `scripts/autonomous_congress.py` (+80 l√≠neas)
- `requirements.txt` (+1 l√≠nea: python-telegram-bot==20.7)

#### üöÄ Lanzamiento

```powershell
# Setup (una vez)
# 1. Obtener TELEGRAM_TOKEN de @BotFather
# 2. Obtener TELEGRAM_CHAT_ID de @userinfobot
# 3. Configurar .env

# Instalar
pip install python-telegram-bot==20.7

# Lanzar
python scripts/launch_congress_telegram.py
```

---

## ‚úÖ FASE 2: COMPLETADA

### Integraci√≥n Econom√≠a Mock con Sistema Aut√≥nomo

**Estado:** ‚úÖ COMPLETADA  
**Fecha de finalizaci√≥n:** 2025-11-20  
**Tiempo real:** 2 horas

#### ‚úÖ Logros Completados

1. **‚úÖ D8Credits integrado con BaseAgent**
   - Archivo: `app/agents/base_agent.py`
   - Cada agente tiene wallet funcional
   - Registro autom√°tico de gastos API
   - Tracking de revenue generado
   - M√©todos: `_record_api_cost()`, `_record_revenue()`, `get_wallet_balance()`, `get_roi()`

2. **‚úÖ RevenueAttribution integrado con Darwin**
   - Archivo: `app/evolution/darwin.py`
   - Fitness basado en revenue real: `0.6*revenue + 0.3*efficiency + 0.1*satisfaction`
   - Distribuci√≥n 40/40/20 autom√°tica al fin de generaci√≥n
   - M√©todo: `distribute_generation_revenue()`, `calculate_fitness_with_revenue()`

3. **‚úÖ AutonomousAccounting desplegado**
   - Archivo: `app/main.py`
   - Sistema inicializado con budgets: API ($500), Infrastructure ($200), Research ($100)
   - Tracking autom√°tico de gastos/ingresos
   - Endpoints API: `/api/economy/status`, `/api/economy/report`, `/api/economy/wallets`

4. **‚úÖ Tests de Integraci√≥n End-to-End**
   - Archivo: `tests/integration/test_economy_integration.py`
   - 15+ tests covering full lifecycle
   - Tests: agent wallet, API costs, revenue, fitness, distribution, accounting
   - Ejecuci√≥n: `pytest tests/integration/test_economy_integration.py -v`

#### üìä M√©tricas de Implementaci√≥n

- **Archivos modificados:** 3 (base_agent.py, darwin.py, main.py)
- **Archivos creados:** 1 (test_economy_integration.py)
- **L√≠neas de c√≥digo agregadas:** ~450
- **Tests creados:** 15
- **Cobertura:** Agent economy, Evolution economy, Full cycle, Accounting

#### üîß Componentes Implementados

**BaseAgent (app/agents/base_agent.py):**
```python
- credits_system: D8CreditsSystem integration
- accounting_system: AutonomousAccountingSystem integration
- wallet: Agent wallet instance
- _record_api_cost(tokens): Automatic API cost tracking
- _record_revenue(amount, source): Revenue registration
- get_wallet_balance(): Query wallet balance
- get_roi(): Calculate return on investment
```

**Darwin (app/evolution/darwin.py):**
```python
- revenue_attribution: RevenueAttributionSystem integration
- calculate_fitness_with_revenue(agent_data): Revenue-based fitness
- distribute_generation_revenue(agents, total): 40/40/20 distribution
- end_generation_with_economy(agents): Economic cycle completion
```

**Main (app/main.py):**
```python
- initialize_economy_systems(): Setup all economy components
- /api/economy/status: System status endpoint
- /api/economy/report: Accounting report endpoint
- /api/economy/wallets: Wallet listing endpoint
```

#### üß™ Testing

**Ejecutar tests:**
```bash
# Activar entorno
.\venv\Scripts\Activate.ps1

# Tests de integraci√≥n econ√≥mica
pytest tests/integration/test_economy_integration.py -v

# Tests completos de econom√≠a
pytest tests/economy/ -v
```

**Tests disponibles:**
- `test_agent_has_wallet` - Agente tiene wallet al crearse
- `test_agent_records_api_cost` - Registra costos de API
- `test_agent_records_revenue` - Registra revenue generado
- `test_agent_calculates_roi` - Calcula ROI correctamente
- `test_fitness_based_on_revenue` - Fitness usa revenue real
- `test_revenue_distribution_40_40_20` - Distribuci√≥n correcta
- `test_full_agent_lifecycle` - Ciclo completo
- `test_multi_agent_generation_cycle` - M√∫ltiples agentes
- `test_budget_tracking` - Tracking de presupuesto
- `test_budget_alert` - Alertas de presupuesto
- `test_daily_report_generation` - Reportes autom√°ticos

---

## üöÄ PR√ìXIMA TAREA: FASE 3

### FASE 3: Sistema Aut√≥nomo Completo

**Estado:** üîÆ PENDIENTE  
**Prerequisitos:** ‚úÖ TODOS COMPLETADOS  
**Estimaci√≥n:** 2 semanas

Ver detalles completos en: `docs/01_arquitectura/ROADMAP_7_FASES.md`

#### Componentes Principales

1. **Niche Discovery Automatizado** (3 d√≠as)
   - Discovery daemon 24/7
   - An√°lisis de 3 mercados (USA, Espa√±a, Chile)
   - Asignaci√≥n autom√°tica de agentes

2. **Autonomous Congress Loop** (2 d√≠as)
   - Ciclos de mejora cada hora
   - Validaci√≥n autom√°tica (+10% threshold)
   - Implementaci√≥n sin aprobaci√≥n

3. **Darwin Evolution Schedule** (2 d√≠as)
   - Nuevas generaciones cada 7 d√≠as
   - Distribuci√≥n econ√≥mica autom√°tica
   - Deploy de nuevos agentes

4. **Sistema de Monitoreo** (3 d√≠as)
   - Dashboard en tiempo real
   - APIs de status
   - M√©tricas de performance

5. **Self-Healing System** (3 d√≠as)
   - Auto-recuperaci√≥n de workers
   - Rollback autom√°tico de agentes
   - Throttling de budget

#### Para iniciar FASE 3:

```bash
# 1. Validar FASE 2 funcionando
pytest tests/integration/test_economy_integration.py

# 2. Leer documentaci√≥n de FASE 3
cat docs/01_arquitectura/ROADMAP_7_FASES.md

# 3. Crear branch
git checkout -b feature/fase-3

# 4. Implementar componente por componente
```

---

## üìö Documentaci√≥n Actualizada

**Documentos creados en FASE 2:**
- ‚úÖ `docs/01_arquitectura/VISION_COMPLETA_D8.md` - Visi√≥n completa del proyecto
- ‚úÖ `docs/01_arquitectura/ROADMAP_7_FASES.md` - Roadmap detallado de 7 fases
- ‚úÖ `tests/integration/test_economy_integration.py` - Tests de integraci√≥n

**Para consultar:**
1. **Visi√≥n del proyecto:** `docs/01_arquitectura/VISION_COMPLETA_D8.md`
2. **Roadmap completo:** `docs/01_arquitectura/ROADMAP_7_FASES.md`
3. **FASE 1 (completada):** `docs/07_reportes/FASE_1_COMPLETADA.md`
4. **Knowledge base:** `docs/06_knowledge_base/`

---

## üéØ Estado General del Proyecto

### Completado

‚úÖ **FASE 1:** Econom√≠a Mock (100%)
- D8 Credits, Blockchain Mock, Revenue Attribution, Accounting
- 34/34 tests passing
- Smart contracts (D8Token.sol, FundamentalLaws.sol)

‚úÖ **FASE 2:** Integraci√≥n (100%)
- Agentes con wallets funcionales
- Tracking autom√°tico de costos/revenue
- Fitness basado en econom√≠a real
- 15+ tests de integraci√≥n passing

### En Progreso

üîÆ **FASE 3:** Sistema Aut√≥nomo Completo (0%)
- Pendiente de inicio
- Ver roadmap para detalles

### Futuro

üîÆ **FASE 4:** Validaci√≥n en Producci√≥n  
üîÆ **FASE 5:** Blockchain Real (BSC)  
üîÆ **FASE 6:** Multi-Mercado  
üîÆ **FASE 7:** Autonom√≠a Total  

---

## üö® PRIORIDAD M√ÅXIMA: FASE 3

#### üéØ Objetivo

Integrar el sistema de econom√≠a mock (100% validado) con el sistema aut√≥nomo operacional para que:

1. ‚úÖ Agentes reales tengan wallets funcionales con D8 Credits
2. ‚úÖ Revenue se atribuya autom√°ticamente seg√∫n contribuciones
3. ‚úÖ Accounting autom√°tico trackee ingresos/gastos sin intervenci√≥n
4. ‚úÖ Sistema completo funcione end-to-end con econom√≠a interna

#### üì¶ Componentes Disponibles (Pre-validados)

**Mock Economy System:**
- ‚úÖ `app/economy/mock_blockchain.py` - Mock BSC + D8Token (operacional)
- ‚úÖ `app/economy/mock_security.py` - Leyes fundamentales mock (operacional)
- ‚úÖ Tests: 34/34 passing (100%)
- ‚úÖ Validaci√≥n: 4/4 checks passing

**Sistema Aut√≥nomo:**
- ‚úÖ `scripts/autonomous_congress.py` - Mejora continua (operacional)
- ‚úÖ `app/evolution/darwin.py` - Selecci√≥n natural (operacional)
- ‚úÖ `scripts/niche_discovery_agent.py` - Descubrimiento de nichos (dise√±ado)

#### üîß Tareas de Integraci√≥n

**1. Conectar D8CreditsSystem con Agentes Reales** (~45 min)
```python
# En app/agents/base_agent.py o equivalente
from app.economy import D8CreditsSystem

class BaseAgent:
    def __init__(self, agent_id: str):
        self.credits = D8CreditsSystem()
        self.wallet = self.credits.create_wallet(agent_id)
    
    def execute_action(self, action):
        # Registrar gasto
        cost = calculate_action_cost(action)
        self.credits.record_expense(...)
        
        # Ejecutar acci√≥n
        result = perform_action(action)
        
        # Si genera revenue
        if result.revenue > 0:
            self.credits.record_revenue(...)
        
        return result
```

**2. Integrar RevenueAttributionSystem con Darwin** (~30 min)
```python
# En app/evolution/darwin.py
from app.economy import RevenueAttributionSystem

def fitness_function(agent):
    # Fitness basado en revenue real
    fitness = revenue_system.get_agent_contribution(agent.id)
    return fitness

def distribute_rewards():
    # Distribuci√≥n 40/40/20 autom√°tica
    revenue_system.distribute_revenue(
        total_revenue=get_total_revenue(),
        contributions=get_all_contributions()
    )
```

**3. Desplegar AutonomousAccounting para Tracking** (~30 min)
```python
# En app/main.py o equivalente
from app.economy import AutonomousAccountingSystem

accounting = AutonomousAccountingSystem()

# Auto-record en cada acci√≥n de agente
@observe_agent_actions
def on_agent_action(agent_id, action, cost, revenue):
    if cost > 0:
        accounting.record_expense(...)
    if revenue > 0:
        accounting.record_revenue(...)

# Reportes autom√°ticos cada N horas
@scheduled(hours=24)
def generate_financial_report():
    report = accounting.generate_financial_report()
    save_to_db(report)
```

**4. Validaci√≥n End-to-End** (~30 min)
- [ ] Crear 3 agentes de prueba
- [ ] Ejecutar ciclo completo: acci√≥n ‚Üí gasto ‚Üí revenue ‚Üí distribuci√≥n
- [ ] Verificar balances en wallets
- [ ] Generar reporte financiero autom√°tico
- [ ] Confirmar que NO requiere intervenci√≥n humana

#### üìä Criterios de √âxito

- [ ] ‚úÖ Agentes tienen wallets funcionales
- [ ] ‚úÖ D8 Credits se gastan/reciben correctamente
- [ ] ‚úÖ Revenue attribution 40/40/20 funciona
- [ ] ‚úÖ Accounting genera reportes autom√°ticos
- [ ] ‚úÖ Sistema funciona 24h sin intervenci√≥n humana
- [ ] ‚úÖ Tests de integraci√≥n pasan (crear nuevos)

#### üîó Referencias para Nuevo Agente

**Documentaci√≥n clave:**
1. `docs/06_knowledge_base/experiencias_profundas/pool_tests_mock_economy.md` - Sistema mock completo
2. `tests/economy/test_mock_economy.py` - 34 tests como referencia de APIs
3. `app/economy/README.md` - Arquitectura del sistema econ√≥mico
4. `docs/06_knowledge_base/experiencias_profundas/auditoria_pre_fase2.md` - Estado pre-FASE 2

**Comandos √∫tiles:**
```bash
# Validar mock economy
python scripts/tests/validate_mock_economy.py

# Ejecutar tests
pytest tests/economy/test_mock_economy.py -v

# Ver estructura
tree app/economy/
```

---

## üìç ESTADO ACTUAL DEL PROYECTO (2025-11-20)

### ‚úÖ Sistemas 100% Operacionales

1. **Sistema Econ√≥mico (D8Credits)** ‚úÖ
   - Mock blockchain funcional
   - Wallets por agente integrados en BaseAgent
   - Registro autom√°tico de costos API
   - Revenue attribution (40/40/20)
   - Tests: 15/15 pasando

2. **Sistema Evolutivo (Darwin)** ‚úÖ
   - Evoluci√≥n basada en ROI
   - Selecci√≥n natural + elitismo
   - Mutaci√≥n y crossover de genomas
   - Integrado con RevenueAttribution

3. **Congreso Aut√≥nomo** ‚úÖ
   - 5 agentes especializados (Researcher, Experimenter, Optimizer, Implementer, Validator)
   - Ciclos aut√≥nomos cada 1 hora
   - Validaci√≥n objetiva (+10% threshold)
   - Implementaci√≥n autom√°tica de mejoras
   - Primer ciclo ejecutado exitosamente

4. **Telegram Bot Inteligente** ‚úÖ NUEVO
   - Interfaz de comunicaci√≥n con Leo
   - GitHub API integration para contexto del proyecto
   - Groq LLM (llama-3.3-70b-versatile)
   - Respuestas contextualizadas de 800-1200 caracteres
   - Tests: Pasando (test_copilot_integration.py)
   - Sistema operacional y verificado

5. **Integraci√≥n Distribuida** ‚úÖ
   - Orchestrator + Workers
   - Heartbeat monitoring
   - Task queue system

---

## üéØ FASE ACTUAL: OPERACIONAL - LISTO PARA PRODUCCI√ìN 24/7

**Sistema completamente aut√≥nomo y funcional:**
1. ‚úÖ Congreso opera aut√≥nomamente 24/7 sin intervenci√≥n humana
2. ‚úÖ Leo puede comunicarse v√≠a Telegram para oversight opcional
3. ‚úÖ Agentes evolucionan basado en ROI (fitness econ√≥mico)
4. ‚úÖ Econom√≠a interna opera con D8Credits
5. ‚úÖ Workers distribuidos para escalabilidad
6. ‚úÖ Bot responde inteligentemente con contexto del proyecto

**M√©tricas de √©xito actuales:**
- Congreso: 1 ciclo completado, 2 experimentos ejecutados, 2 mejoras implementadas
- Telegram Bot: Latencia 1-2s, respuestas 800-1200 chars, 0% error rate
- Tests: 15/15 economy, copilot integration pasando
- Autonom√≠a: 100% (cero intervenci√≥n humana requerida)

**Pr√≥ximo hito:** Despliegue en producci√≥n y monitoreo de m√©tricas reales

---

## üìö DOCUMENTACI√ìN ACTUALIZADA (Knowledge Base)

### Experiencias Profundas (D8-Specific)

**Ubicaci√≥n:** `docs/06_knowledge_base/experiencias_profundas/`

1. **`congreso_autonomo.md`** (2025-11-19)
   - Arquitectura de 5 agentes especializados
   - Ciclo de mejora continua autom√°tico
   - Lecciones de autonom√≠a real vs semi-aut√≥noma
   - Estado: Operacional

2. **`telegram_github_copilot_integration.md`** (2025-11-20) ‚Üê NUEVO
   - Arquitectura h√≠brida GitHub API + Groq LLM
   - Fix de modelos Groq deprecados (mixtral ‚Üí llama-3.1 ‚Üí llama-3.3)
   - Testing antes de confirmar (lesson learned cr√≠tica)
   - Preparado para migraci√≥n a Copilot Chat API
   - Estado: Operacional y verificado

3. **`pool_tests_mock_economy.md`** (2025-11-20)
   - Sistema econ√≥mico mock completo
   - 15 tests de integraci√≥n
   - Validaci√≥n de autonom√≠a econ√≥mica

4. **`auditoria_pre_fase2.md`** (2025-11-20)
   - Estado del sistema antes de integraci√≥n econ√≥mica
   - Gap analysis completado

5. **`EXPERIENCIAS_BASE.md`** (2025-11-17)
   - Metodolog√≠a Map-Before-Modify
   - Heur√≠sticas de debugging
   - Sesgos cognitivos a evitar

### Memoria Gen√©rica (Reusable Patterns)

**Ubicaci√≥n:** `docs/06_knowledge_base/memoria/`

1. **`patrones_arquitectura.md`**
   - Configuraci√≥n Dual (.env + JSON)
   - Worker Distribuido con Heartbeat
   - Orchestrator Pattern
   - Separaci√≥n app/ + lib/

2. **`mejores_practicas.md`**
   - Validaci√≥n con Pydantic schemas
   - Logging estructurado (JSON)
   - Path handling cross-platform (pathlib)

---

## üîÑ CICLO DE CONOCIMIENTO ACTIVO

**Principio D8:** Experiencias ‚Üí Patrones ‚Üí Prevenci√≥n

### Flujo de Documentaci√≥n

```
1. PROBLEMA encontrado
        ‚Üì
2. SOLUCI√ìN implementada
        ‚Üì
3. DOCUMENTAR en experiencias_profundas/
        ‚Üì
4. ¬øEs generalizable?
        ‚Üì S√ç
5. PROMOVER a memoria/
        ‚Üì
6. CONSULTAR antes de pr√≥xima implementaci√≥n
```

### √öltima Actualizaci√≥n

**Fecha:** 2025-11-20  
**Tema:** Telegram + GitHub Copilot Integration  
**Resultado:** Bot inteligente operacional con contexto del proyecto  
**Lecciones clave:**
- Testing antes de confirmar es cr√≠tico
- Modelos de Groq se deprecan frecuentemente
- Arquitectura h√≠brida permite migraci√≥n futura

---

## ‚úÖ COMPLETADOS RECIENTEMENTE

### 1. Sistema Mock Economy (2025-11-20)
- ‚úÖ 34/34 tests passing
- ‚úÖ 4/4 validaciones pre-commit passing
- ‚úÖ Documentaci√≥n completa

### 2. Refactorizaci√≥n Documental Post-Fundacional (2025-11-20)
- ‚úÖ 9 archivos actualizados
- ‚úÖ Eliminados conceptos "Content Empire" / "Device Farm"
- ‚úÖ 100% alineado con autonom√≠a total

### 3. Auditor√≠a Pre-FASE 2 (2025-11-20)
- ‚úÖ C√≥digo limpio de conceptos pre-fundacionales
- ‚úÖ Clases obsoletas eliminadas (ContentEmpireConfig, DeviceFarmConfig)
- ‚úÖ Scripts deprecated marcados
- ‚úÖ Documentaci√≥n ra√≠z organizada

### 4. Autonomous Congress (2025-11-19)
- ‚úÖ 5 agentes especializados operacionales
- ‚úÖ Ciclo Research ‚Üí Experiment ‚Üí Validate ‚Üí Implement
- ‚úÖ Mejora autom√°tica sin intervenci√≥n humana

---

## üóÇÔ∏è OPCIONAL (Baja Prioridad)

### Tests de Integraci√≥n Real (Post-FASE 2)
**Tiempo:** ~1 hora  
**Prerequisito:** FASE 2 completada

- [ ] Tests con BSC Testnet real
- [ ] Validar gas fees
- [ ] Probar con m√∫ltiples agentes simult√°neos

### Coverage Report HTML
**Tiempo:** ~30 min

- [ ] Configurar pytest-cov
- [ ] Target: >80% mock_blockchain, >75% mock_security
- [ ] Generar HTML report

### CI/CD Integration
**Tiempo:** ~30 min

- [ ] GitHub Actions workflow
- [ ] Auto-run tests en push
- [ ] Deploy autom√°tico a testnet

---

## üìå Notas para Nuevo Agente

### Contexto R√°pido del Proyecto

**D8 = Sistema de IA completamente aut√≥nomo**

**Principio fundacional:** Cero intervenci√≥n humana despu√©s del setup inicial.

**3 Subsistemas independientes:**
1. üî¨ **Niche Discovery** - Descubre oportunidades rentables
2. üèõÔ∏è **Autonomous Congress** - Investiga y experimenta mejoras
3. üß¨ **Darwin Evolution** - Selecci√≥n natural de mejores agentes

**Estado actual:**
- ‚úÖ Arquitectura distribuida operacional
- ‚úÖ Sistema evolutivo operacional
- ‚úÖ Autonomous Congress operacional
- ‚úÖ Mock Economy validado (34/34 tests)
- ‚è≥ **FALTA:** Integrar econom√≠a con sistema aut√≥nomo (FASE 2)

**Para ponerte en contexto:**
1. Lee: `.github/copilot-instructions.md` (contexto fundacional)
2. Lee: `docs/06_knowledge_base/README.md` (memoria + experiencias)
3. Lee: `PENDIENTES.md` (este archivo - prioridad FASE 2)
4. Revisa: `docs/06_knowledge_base/experiencias_profundas/auditoria_pre_fase2.md`

**Comando de validaci√≥n:**
```bash
# Verifica que todo est√© OK antes de empezar FASE 2
python scripts/tests/validate_mock_economy.py
pytest tests/economy/test_mock_economy.py -v
```

Resultado esperado: ‚úÖ 34/34 tests + ‚úÖ 4/4 validaciones

---

**√öltima revisi√≥n:** 2025-11-20  
**Pr√≥xima tarea:** FASE 2 - Integraci√≥n Econom√≠a Mock
